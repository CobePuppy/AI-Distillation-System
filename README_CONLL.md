# CoNLL-2003 NER 工作流测试 (中文版)

这个项目是用来跑 CoNLL-2003 数据集的命名实体识别 (NER) 任务的。简单说就是让几个模型配合起来干活。

## 这里的门道 (架构说明)

咱们这个工作流主要有三个角色：
1.  **Model A (本地小弟)**: 也就是那个 0.5B 的 Qwen 模型，跑得快但脑子可能不太好使，负责出初稿。
2.  **Model C (线上老师傅)**: DeepSeek 的大模型 (R1)，脑子好使但要花钱/费流量，负责给标准答案。
3.  **Model B (改作业的)**: 也是本地模型，负责看着老师傅的答案，把小弟的作业改改好。

## 准备工作

1.  **Python 环境**: 记得激活虚拟环境，别裸奔。
2.  **依赖库**: `datasets` 库得装好，不然数据下不下来。
3.  **模型准备**:
    *   本地模型 (Model A/B) 应该已经在 `models_cache/` 里躺好了。
    *   线上模型 (Model C) 需要你在 `config.py` 里填好 DeepSeek 的 API Key。

## 文件是干啥的

*   `conll_loader.py`: 负责去 Hugging Face 搬运 CoNLL-2003 数据集。如果网不好，它会贴心地给你塞点假数据，保证程序不崩。
*   `run_conll_test.py`: 启动脚本。它会把环境设好（比如换个国内镜像源），然后指挥大家干活。
*   `workflow_manager.py`: 大管家，负责协调 A、B、C 三个模型。

## 怎么跑

在终端里敲这个就行：

```bash
python run_conll_test.py
```

跑起来之后会发生什么：
1.  先去搞 1 条 CoNLL-2003 的验证集数据（为了省时间先只跑 1 条）。
2.  拼凑个提示词，告诉模型“把人名、地名啥的给我找出来”。
3.  Model A 先做，Model C 再做，最后 Model B 抄作业修正。
4.  结果会保存在 `results/` 目录下，文件名大概长这样 `result_conll_val_<id>.txt`。

---
*注：如果遇到网络问题，脚本里已经写了 fallback 逻辑，会自动切换到 dummy 数据，稳得很。*
